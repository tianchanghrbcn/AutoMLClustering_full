#!/usr/bin/env python
# coding: utf-8

import sys
import os
import pandas as pd
import json
import re
import asyncio
import time
import datetime
import google.generativeai as genai

# ---------------------------------------------------------
# 1. é…ç½® Google Gemini API
# ---------------------------------------------------------
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("âš ï¸ GOOGLE_API_KEY not found. Please set it in the environment variables.")

genai.configure(api_key=GOOGLE_API_KEY)


# ---------------------------------------------------------
# 2. CSV è¯»å–ä¸å¤„ç†
# ---------------------------------------------------------
def load_csv(file_path: str) -> pd.DataFrame:
    """Load CSV into a pandas DataFrame."""
    df = pd.read_csv(file_path)
    return df


def batch_processing(df: pd.DataFrame, batch_size: int = 50):
    """Yield consecutive 50-row batches from the DataFrame."""
    for i in range(0, len(df), batch_size):
        yield i, df.iloc[i: i + batch_size].reset_index(drop=True)


# ---------------------------------------------------------
# 3. Prompt ç”Ÿæˆå‡½æ•°
# ---------------------------------------------------------
def create_prompt(df: pd.DataFrame) -> str:
    """Generate a structured prompt for Gemini based on the DataFrame sample."""
    column_names = df.columns.tolist()
    sample_data = df.to_dict(orient="records")  # convert a batch of rows to a list of dicts

    # åœ¨ Prompt ä¸­æ˜ç¡®è¯´æ˜åªè¿”å› JSON
    prompt = f"""
You are a data analysis expert. Below is a dataset with column names and sample data:

Column Names:
{column_names}

Sample Data (max 50 rows in this batch):
{sample_data}

Please analyze potential errors and return a JSON structure with detected errors per row:

1. Missing Values
2. Formatting Errors (dates, emails, phone numbers)
3. Spelling Errors (names, cities, companies)
4. Outliers in numerical fields
5. Dependency Errors (invalid date logic, mismatched country-capital, etc.)

IMPORTANT:
- You must return a single JSON object with the exact format:
{{
  "row_index": {{
    "column_name": "Error description",
    "another_column": "Error description"
  }},
  "another_row_index": {{
    ...
  }}
}}
- If there are no errors, return an empty JSON {{}}.
- Do NOT include explanations, disclaimers, or markdown formatting.
- The JSON must start with {{ and end with }}.
""".strip()

    return prompt


# ---------------------------------------------------------
# 4. å‘ Gemini å‘é€è¯·æ±‚çš„å‡½æ•°
# ---------------------------------------------------------
def gemini_request(
        df: pd.DataFrame,
        batch_start_idx: int,
        batch_num: int,
        requests_history: list,
        max_retries: int = 3
):
    """Send prompt to Gemini 2.0 Pro and parse JSON response."""
    prompt = create_prompt(df)
    request_time = datetime.datetime.now().isoformat()

    for attempt in range(max_retries):
        try:
            # 1) æŒ‡å®š Gemini 2.0 Pro (å¯èƒ½åç§°éšç‰ˆæœ¬å˜åŒ–)
            model = genai.GenerativeModel(model_name='gemini-2.0-flash')
            response = model.generate_content(prompt)

            # 2) å–åˆ°å“åº”æ–‡æœ¬
            raw_response_text = response.text.strip() if response and response.text else ""

            # 3) æ„å»ºäº¤äº’è®°å½•
            interaction_record = {
                "batch_num": batch_num,
                "attempt": attempt + 1,
                "request_time": request_time,
                "prompt": prompt,
                "gemini_raw_response": raw_response_text
            }

            # 4) ç©ºå“åº”å¤„ç†
            if not raw_response_text:
                interaction_record["parsed_issues"] = {}
                interaction_record["error"] = "Empty response"
                requests_history.append(interaction_record)
                return raw_response_text, {}

            # 5) å°è¯•è§£æ JSON
            try:
                issues = json.loads(raw_response_text)
                if not isinstance(issues, dict):
                    raise ValueError("Returned JSON is not a dictionary")
            except (json.JSONDecodeError, ValueError) as e:
                interaction_record["parsed_issues"] = {}
                interaction_record["error"] = f"JSON parsing failed: {e}"
                requests_history.append(interaction_record)
                return raw_response_text, {}

            # 6) å¤„ç†è¡Œå·ä¿®æ­£ï¼ˆå¦‚æœæ¨¡å‹è¿”å› "row_index"ï¼‰
            corrected_issues = {}
            for row_index_str, row_errors in issues.items():
                try:
                    numeric_row = int(row_index_str)
                    corrected_index = batch_start_idx + numeric_row
                    corrected_issues[str(corrected_index)] = row_errors
                except ValueError:
                    # å¦‚æœé”®ä¸æ˜¯æ•°å­—ï¼Œåˆ™ä¿ç•™åŸé”®
                    corrected_issues[row_index_str] = row_errors

            # 7) è®°å½•å¹¶è¿”å›
            interaction_record["parsed_issues"] = corrected_issues
            requests_history.append(interaction_record)
            return raw_response_text, corrected_issues

        except Exception as e:
            print(f"âš ï¸ Gemini request failed [batch {batch_num} attempt {attempt + 1}/{max_retries}]: {e}")
            time.sleep(5)

    print(f"âŒ [batch {batch_num}] API request failed after {max_retries} retries")
    return "", {}


# ---------------------------------------------------------
# 5. ç»“æœä¿å­˜ã€è§£æä¸åˆå¹¶
# ---------------------------------------------------------
def save_json(data, output_file: str):
    """Save Python object to a JSON file."""
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
    except Exception as e:
        print(f"âŒ Failed to save {output_file}: {e}")


def parse_raw_responses(raw_responses_file: str):
    """Parse the raw responses file to aggregate final issues."""
    try:
        with open(raw_responses_file, "r", encoding="utf-8") as f:
            raw_responses = json.load(f)

        consolidated_issues = {}
        for batch in raw_responses:
            try:
                response_text = batch.get("raw_response", "").strip()
                if not response_text:
                    print(f"âš ï¸ Skipping empty response: batch {batch['batch_num']}")
                    continue

                cleaned_text = re.sub(r"```(json)?\s*|\s*```", "", response_text).strip()

                try:
                    issues = json.loads(cleaned_text)
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON parsing failed for batch {batch['batch_num']}: {e}")
                    continue

                if isinstance(issues, dict) and issues:
                    consolidated_issues.update(issues)
                else:
                    print(f"âš ï¸ batch {batch['batch_num']}: data is empty or invalid.")
            except Exception as e:
                print(f"âŒ Unexpected error in batch {batch['batch_num']}: {e}")

        return consolidated_issues

    except Exception as e:
        print(f"âŒ Failed to read {raw_responses_file}: {e}")
        return {}


# ---------------------------------------------------------
# 6. ä¸»æµç¨‹ï¼šæ‰¹æ¬¡åˆ†æ + å­˜å‚¨ç»“æœ + è§£ææ±‡æ€»
# ---------------------------------------------------------
async def detect_with_gemini(df: pd.DataFrame):
    requests_history = []
    consolidated_issues = {}
    all_raw_responses = []

    for batch_num, (batch_start_idx, batch_df) in enumerate(batch_processing(df, batch_size=50)):
        print(f"ğŸš€ Processing batch {batch_num} (rows {batch_start_idx} to {batch_start_idx + len(batch_df) - 1})...")
        raw_response, issues = gemini_request(batch_df, batch_start_idx, batch_num, requests_history)
        all_raw_responses.append({
            "batch_num": batch_num,
            "raw_response": raw_response
        })
        consolidated_issues.update(issues)

    save_json(all_raw_responses, "raw_gemini_responses.json")
    return consolidated_issues


# ---------------------------------------------------------
# 7. ä¸»å…¥å£
# ---------------------------------------------------------
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python google_gemini_detection.py <csv_path>")
        sys.exit(1)

    csv_path = sys.argv[1]  # ä»å‘½ä»¤è¡Œè·å– CSV æ–‡ä»¶è·¯å¾„

    start_time = time.time()

    # è¯»å–æŒ‡å®šè·¯å¾„çš„ CSV
    df = load_csv(csv_path)

    # é’ˆå¯¹ Windows çš„äº‹ä»¶å¾ªç¯ç­–ç•¥
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    final_issues = asyncio.run(detect_with_gemini(df))

    # äºŒæ¬¡è§£æ raw_gemini_responses.json å¹¶åˆå¹¶
    final_parsed_issues = parse_raw_responses("raw_gemini_responses.json")
    if final_parsed_issues:
        final_issues.update(final_parsed_issues)

    output_file = "gemini_detections.json"
    save_json(final_issues, output_file)

    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"â³ Program execution time: {elapsed_time:.2f} seconds")
